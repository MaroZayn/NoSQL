{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic storage format for unstructured data.\n",
    "\n",
    "The first thing to do before thinking about how to store unstructured data is to understand the difference between structured and unstructured data. \n",
    "\n",
    "## Structured vs Unstructured vs Semi-structured.\n",
    "\n",
    "Structured Data:\n",
    "- Row and column format (or can be easily converted to row and column)\n",
    "- Fixed length/width\n",
    "- Missing values = Blank\n",
    "- Storing tools: CSV, TXT, XLS.\n",
    "\n",
    "Semi-Structured or Unstructured Data:\n",
    "- Contains tags,keys or other markers.\n",
    "- Nested or hierarchical data.\n",
    "- Avoid messy translations into a relational data mode.\n",
    "- storing tools: JSON, XML, HTML, Pickle.\n",
    "\n",
    "N.B: Unstructured Data might be an abuse of language. Every data is structured in some way or your computer would not be able to understand it. Data is atleast semi-structured. Information in the other hand... An image has structured date (pixel by pixel, author, date, type,...) but the information present on an image is unstructure (The computer does not understand that on the image there's a \"red car\", as an observer you structure this information by gathering the pixel and the information becomes structured)\n",
    "\n",
    "## Dict\n",
    "\n",
    "A dictionary is a collection which is unordered, changeable and indexed also called keys (i.e it stores semi-structured data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'authors': ['Auteur1', 'Auteur2', 'Auteur3'], 'title': 'This is paper 1', 'affiliations': ['University of Mannheim', 'University of Strasbourg'], 'ref': ['This is ref 1', 'This is ref 2', 'This is ref 3']}\n",
      "<class 'dict'>\n",
      "['__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n"
     ]
    }
   ],
   "source": [
    "paper = {\"authors\" : [\"Auteur1\",\"Auteur2\",\"Auteur3\"],\n",
    "         \"title\" : \"This is paper 1\",\n",
    "         \"affiliations\" : [\"University of Mannheim\",\"University of Strasbourg\"],\n",
    "         \"ref\" : [\"This is ref 1\",\"This is ref 2\",\"This is ref 3\"]}\n",
    "print(paper)\n",
    "print(type(paper))\n",
    "print(dir(paper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1: Create a dict from the paper of [lecun et al.](https://www.researchgate.net/publication/277411157_Deep_Learning) and [goodfellow et al.](https://arxiv.org/abs/1406.2661) with authors, title, affiliations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's multiple options to save a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'authors': ['Auteur1', 'Auteur2', 'Auteur3'], 'title': 'This is paper 1', 'affiliations': ['University of Mannheim', 'University of Strasbourg'], 'ref': ['This is ref 1', 'This is ref 2', 'This is ref 3']}\n",
      "<class 'dict'>\n",
      "['__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n"
     ]
    }
   ],
   "source": [
    "# JSON\n",
    "import json\n",
    "with open('data/data.json', 'w') as fp:\n",
    "    json.dump(paper, fp)\n",
    "    \n",
    "with open('data/data.json', 'r') as fp:\n",
    "    test= json.load(fp)\n",
    "\n",
    "print(test)\n",
    "print(type(test))\n",
    "print(dir(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: save your dict with the 2 papers and load it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'authors': ['Auteur1', 'Auteur2', 'Auteur3'], 'title': 'This is paper 1', 'affiliations': ['University of Mannheim', 'University of Strasbourg'], 'ref': ['This is ref 1', 'This is ref 2', 'This is ref 3']}\n",
      "<class 'dict'>\n",
      "['__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n"
     ]
    }
   ],
   "source": [
    "# Pickle\n",
    "import pickle\n",
    "\n",
    "with open('data/data.pickle', 'wb') as fp:\n",
    "    pickle.dump(paper, fp)\n",
    "\n",
    "with open('data/data.pickle', 'rb') as fp:\n",
    "    test = pickle.load(fp)\n",
    "\n",
    "print(test)\n",
    "print(type(test))\n",
    "print(dir(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Zhuolin'] ['Yong'] ['Zhuolin'] ['1', '†']\n",
      "['Linmei'] ['Zhuang'] ['Linmei'] ['1', '†']\n",
      "['Yi'] ['Liu'] ['Yi'] ['1']\n",
      "['Xin'] ['Deng'] ['Xin'] ['2']\n",
      "['Dingde'] ['Xu'] ['Dingde'] ['3', '*']\n"
     ]
    }
   ],
   "source": [
    "# XML, Extensible Markup Language. tree-like structure.\n",
    "# Multiple package to work with python and xml: lxml, xml.dom.minidom, xml.etree.ElementTree\n",
    "# We will use lxml but make sure to look at the docs of others.\n",
    "\n",
    "import lxml.etree\n",
    "\n",
    "# Load the data\n",
    "xml_file = \"data/xml_file.nxml\"\n",
    "root = lxml.etree.parse(xml_file)\n",
    "\n",
    "# Prettify = Make it human readable\n",
    "# print(lxml.etree.tostring(root, encoding=\"unicode\", pretty_print=True)) \n",
    "\n",
    "# xml format: <TAG1 ATTRIBUTE1><TAG2 ATTRIBUTE2> TEXT </ENDTAG2></ENDTAG1>\n",
    "# TAG2 is a children node of TAG1\n",
    "# read more about it here https://www.w3schools.com/html/html_elements.asp\n",
    "\n",
    "# To access elements we use something called XPATH\n",
    "# xpath(\"//TAG1[ATTRIBUTE1='something']/TAG2[ATTRIBUTE2='something']/text()\")\n",
    "\n",
    "abstract = root.xpath(\"//abstract//text()\")\n",
    "body = root.xpath(\"//body//text()\")\n",
    "title = root.xpath(\"//title-group//text()\")\n",
    "figures = root.xpath(\"//fig//text()\")\n",
    "\n",
    "aff = root.xpath(\"//aff/text()\")\n",
    "aff = [i for i in aff if not i.startswith((' ', '\\t'))]\n",
    "aff_label = root.xpath(\"//aff/label/text()\")\n",
    "\n",
    "mails =root.xpath(\"//author-notes/corresp\")[0]\n",
    "mails.getchildren()\n",
    "\n",
    "xref = {}\n",
    "for affiliation,label in zip(aff,aff_label):\n",
    "    xref[label]= affiliation\n",
    "\n",
    "authors = root.xpath(\"//contrib\")\n",
    "authors = [i.getchildren() for i in authors]\n",
    "for author in authors:\n",
    "    names = [i.getchildren() for i in author if i.tag == \"name\"][0]\n",
    "    surname = [i.text for i in names if i.tag==\"surname\"]\n",
    "    name = [i.text for i in names if i.tag==\"given-names\"]\n",
    "    xrefs = [i.text for i in author if i.tag==\"xref\"]\n",
    "    print(name,surname,name,xrefs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 3:  do the same but for the xml_file2 put infos in a dict and save it in a json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine you have huge amount of semi-structured data in form of a dict. For example you can request 30M tweets with the name of the person who tweeted, the text, the date, the language, the comments,...\n",
    "\n",
    "You could store it in a JSON or a Pickle file. Problem arise when you try to open it back. You maybe don't want to load every tweets in your memory (RAM and time issues) but with these format there's no other choices. Maybe you also want to store this 30M on an other machine and connect to it from a small laptop. All of this shows you the limitation of storing semi-structured data.\n",
    "\n",
    "As for the structured format where you went from csv to SQL DBs you can also go from JSON to noSQL DBs. That's what MongoDB is and we will learn to use it in the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoSQL types\n",
    "\n",
    "Multiple type of NoSQL DB exist. The most popular are written below\n",
    "\n",
    "- Key-value stores \n",
    "- Document stores \n",
    "- Wide column stores\n",
    "- Graph databases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key-value stores\n",
    "\n",
    "A key-value store is the simplest possible data model: it's a storage system that stores values indexed by a key (kinda like a dict). The key is generaly an id, identifier or a primary key and the value associated is a binary object, the system does not really handle the value (blackbox). CRUD operations does exist on key-value stores (More on CRUD operation in Chap II).\n",
    "\n",
    "pros: scalable and fast\n",
    "cons: for simple data and simple queries (query limited on key since values are black-box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### document stores\n",
    "\n",
    "A document-oriented database extends the key-values model in the sense that values are stored in a structured format called document that the database can understand (i.e it's no longer a blackbox). Therefore you are no longer limited in the queries and you can perform CRUD operations on keys but also values. This allows the user to fetch entire page of information (for example blogs that contain a specific keyword) and is much more appreciated by websites storing a lot of informations.\n",
    "La structure d'un document stores est la suivante: DB-collection-Document. CRUD operations also available.\n",
    "\n",
    "pros: Extension of key-value (value examinable), complex query.\n",
    "cons: Slow for updating (not a problem as long you can have your index in RAM), difficult to query when keys are constantly changing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide column store\n",
    "\n",
    "\"It uses tables, rows, and columns, but unlike a relational database, the names and format of the columns can vary from row to row in the same table\" (wikipedia) i.e it's more flexible than the typical SQL DB but it's not the only difference. In some wide column DB you need to specify fields (cassandra) others you don't. CRUD operations available. Read by rows (a key is assigned to each row)\n",
    "\n",
    "pros: works well with flat data with similar scheme\n",
    "cons: No ACID transactions, no complex query (Average, sum,...), hard to change the structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph DBs\n",
    "\n",
    "DB that consists of nodes (individuals/agent) which are connected by edges (relation between the two individuals). Each node and edge have proprety (e.g individuals has different characteristics and they are connected in a certain way defined by the property)\n",
    "\n",
    "pros and cons can be resumed by the fact that they are specific to graph data and nothing else.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about types of NoSQL DB here https://www.ksi.mff.cuni.cz/~svoboda/courses/2016-2-MIE-PDB/lectures/Lecture-06-NoSQL.pdf.\n",
    "\n",
    "Refer to this website if you are interested in seeing the most used db knowing each type. https://db-engines.com/en/ranking\n",
    "\n",
    "- key-value: #1 ranked is Redis\n",
    "- Document-oriented: #1 is MongoDB\n",
    "- Wide columns: #1 is Cassandra\n",
    "- Graph: #1 is Neo4j\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
